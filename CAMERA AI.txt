




pip install flask opencv-python --break-system-packages

sudo usermod -aG video $USER






#!/bin/bash
while true
do
  echo "=== Iniciando MirakoCAM ==="
  python3 /root/app.py
  echo ">>> Flask parou (exit code: $?) — reiniciando em 5s..."
  sleep 5
done

chmod +x run_cam.sh
./run_cam.sh












pip uninstall -y opencv-python opencv-python-headless --break-system-packages

sudo apt update
sudo apt install python3-opencv ffmpeg


pip uninstall numpy
pip install numpy==1.26.0

##BAIXAR MODELOS 

#!/usr/bin/env bash
set -euo pipefail

MODEL_DIR="models"
mkdir -p "$MODEL_DIR"

# Nomes finais no disco
PROTO="$MODEL_DIR/deploy.prototxt"
WEIGHTS="$MODEL_DIR/mobilenet_iter_73000.caffemodel"

# Origens preferidas (projeto original)
PROTO_URLS=(
  "https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/deploy.prototxt"
  "https://github.com/chuanqi305/MobileNet-SSD/raw/master/deploy.prototxt"
)

WEIGHTS_URLS=(
  "https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/mobilenet_iter_73000.caffemodel"
  "https://github.com/chuanqi305/MobileNet-SSD/raw/master/mobilenet_iter_73000.caffemodel"
  # Fallbacks comunitários (use só se necessário)
  "https://github.com/mesutpiskin/opencv-object-detection/raw/master/data/dnnmodel/MobileNetSSD_deploy.caffemodel"
  "https://sourceforge.net/projects/ip-cameras-for-vlc/files/MobileNetSSD_deploy.caffemodel/download"
)

download_any() {
  local out="$1"; shift
  for url in "$@"; do
    echo "[*] tentando: $url"
    if command -v curl >/dev/null 2>&1; then
      if curl -L --fail --retry 3 -o "$out" "$url"; then
        echo "[OK] baixado de: $url"
        return 0
      fi
    else
      if wget -O "$out" "$url"; then
        echo "[OK] baixado de: $url"
        return 0
      fi
    fi
  done
  return 1
}

echo "[*] Baixando prototxt..."
if [ ! -s "$PROTO" ]; then
  download_any "$PROTO" "${PROTO_URLS[@]}" || {
    echo "[ERRO] não consegui baixar o prototxt. Baixe manualmente e salve em: $PROTO"
    exit 1
  }
fi

echo "[*] Baixando caffemodel..."
if [ ! -s "$WEIGHTS" ]; then
  download_any "$WEIGHTS" "${WEIGHTS_URLS[@]}" || {
    echo "[ERRO] não consegui baixar o caffemodel. Baixe manualmente e salve em: $WEIGHTS"
    exit 1
  }
fi

echo "[OK] Modelos prontos em: $MODEL_DIR"
ls -lh "$PROTO" "$WEIGHTS"











# Dependências básicas
sudo apt-get update && sudo apt-get install -y curl ca-certificates xz-utils

# Descobre a sua arquitetura e escolhe o asset certo
ARCH=$(dpkg --print-architecture)               # armhf ou arm64
case "$ARCH" in
  arm64)  FILTER="linux_arm64" ;;
  armhf)  FILTER="linux_armv7|linux_arm" ;;     # armv7 (fallback: arm genérico)
  *)      echo "Arquitetura $ARCH não mapeada"; exit 1 ;;
esac

# Busca a URL do .deb (preferência) ou do .gz na última release
URL=$(curl -s https://api.github.com/repos/jpillora/chisel/releases/latest \
  | grep -oP '(?<="browser_download_url": ")[^"]+' \
  | grep -E "chisel_.*_(${FILTER})\.(deb|gz)$" | head -n1)

# Instala (.deb se houver; senão, extrai o .gz)
if echo "$URL" | grep -q '\.deb$'; then
  curl -L "$URL" -o /tmp/chisel.deb && sudo dpkg -i /tmp/chisel.deb || sudo apt -f install -y
else
  curl -L "$URL" -o /tmp/chisel.gz && gunzip -f /tmp/chisel.gz && \
  chmod +x /tmp/chisel && sudo mv /tmp/chisel /usr/local/bin/chisel
fi

# Verifique
chisel -v


##PROXY REVERSO NGINX 

# All server fields such as server | location can be set, such as:
# location /web {
#     try_files $uri $uri/ /index.php$is_args$args;
# }
# error_page 404 /diy_404.html;
# If there is abnormal access to the reverse proxy website and the content has already been configured here, please prioritize checking if the configuration here is correct

# --- Upstreams dinâmicos por Referer (um ponto de verdade) ---
# Fallback (raiz)
set $api_upstream http://127.0.0.1:6000;
set $static_upstream http://127.0.0.1:6000;

# Se a página de origem é /web1/, use 15000
if ($http_referer ~* "/web1/") {
    set $api_upstream http://127.0.0.1:15000;
    set $static_upstream http://127.0.0.1:15000;
}

# Se a página de origem é /cam1/, use 15001
if ($http_referer ~* "/cam1/") {
    set $api_upstream http://127.0.0.1:15001;
    set $static_upstream http://127.0.0.1:15001;
}

# --- OPCIONAL: se os endpoints de gravação forem SEMPRE do cam1 ---
# Coloque ANTES do /api/ geral para ter prioridade
location ^~ /api/record/ {
    proxy_pass http://127.0.0.1:15001;  # cam1
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    proxy_http_version 1.1;
    proxy_buffering off;
    proxy_request_buffering off;
    proxy_read_timeout 3600s;
    proxy_send_timeout 3600s;
    client_max_body_size 100m;
}

# --- /api (ÚNICO bloco) ---
location ^~ /api/ {
    proxy_pass $api_upstream;  # mantém /api/... para o app selecionado pelo Referer
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    proxy_http_version 1.1;
    proxy_buffering off;             # evita buffering de respostas longas/stream
    proxy_request_buffering off;     # encaminha o body (POST/PUT) sem buffer
    proxy_read_timeout 3600s;
    proxy_send_timeout 3600s;
    client_max_body_size 100m;
    # Se usar WebSocket em /api/:
    # proxy_set_header Upgrade $http_upgrade;
    # proxy_set_header Connection "upgrade";
}

# --- Stream de vídeo ---
location ^~ /video_feed {
    proxy_pass $static_upstream;     # preserva query (?dev=/dev/videoX)
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    proxy_http_version 1.1;
    proxy_buffering off;
    proxy_request_buffering off;
    proxy_read_timeout 3600s;
    add_header X-Accel-Buffering no;
    # Se for WebSocket:
    # proxy_set_header Upgrade $http_upgrade;
    # proxy_set_header Connection "upgrade";
}

# --- Imagens/Thumbs ---
location ^~ /media/ {
    proxy_pass $static_upstream;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;

    proxy_buffering off;             # evita atraso em geração on-demand
    expires -1;
    add_header Cache-Control "no-store";
}

# --- Conveniências ---
# Força barra final nas apps (resolve assets relativos)
location = /web1 { return 301 /web1/; }
location = /cam1 { return 301 /cam1/; }

# Redireciona a raiz para /web1/ (ou troque para /cam1/ se preferir)
location = / { return 302 /web1/; }






tee /etc/systemd/system/chisel-client.service >/dev/null <<'EOF'
[Unit]
Description=Chisel client (reversos: 15000->127.0.0.1:80 e 15001->127.0.0.1:5000)
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
User=orangepi
Environment="PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin"
ExecStart=/usr/bin/env chisel client \
  --keepalive 10s \
  --auth camai:qazwsx \
  camai.mirako.org:6000 \
  R:0.0.0.0:15000:127.0.0.1:80 \
  R:0.0.0.0:15001:127.0.0.1:5000
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target


EOF


sudo systemctl daemon-reload
sudo systemctl enable --now chisel-client
sudo systemctl restart chisel-client
journalctl -u chisel-client -f









finalmente o codigo 




//app.py

tee /root/app.py >/dev/null <<'EOF'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os, cv2, time, glob, threading, platform, subprocess, re, json, stat
from datetime import datetime, date
from flask import Flask, Response, jsonify, render_template_string, request, send_from_directory, abort
from werkzeug.middleware.proxy_fix import ProxyFix

# ----------------- Pastas -----------------
MEDIA = {"photos": "photos", "videos": "videos", "thumbs": "thumbs"}
for d in MEDIA.values():
    os.makedirs(d, exist_ok=True)

# ----------------- Config persistente -----------------
CONFIG_FILE = "config.json"
CFG_LOCK = threading.Lock()
CFG = {
    "cameras": {},
    "ui": {"preview_size": "medium", "library_view": "grid"}
}

def _cfg_load():
    global CFG
    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            with CFG_LOCK:
                loaded = json.load(f)
                loaded.setdefault("ui", {})
                loaded["ui"].setdefault("preview_size", "medium")
                loaded["ui"].setdefault("library_view", "grid")
                loaded["ui"].setdefault("selected_devs", [])
                loaded.setdefault("cameras", {})
                for k, c in loaded["cameras"].items():
                    c.setdefault("mic", "default")
                    c.setdefault("timelapse", {"enable": False, "interval": 5})
                    c.setdefault("motion", {
                        "enable": False, "sensitivity": 50, "min_area_pct": 3,
                        "action": "photo", "overlay": True, "cooldown": 10, "clip_len": 30
                    })
                CFG = loaded
    except Exception:
        pass

def _cfg_save():
    with CFG_LOCK:
        tmp = CONFIG_FILE + ".tmp"
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(CFG, f, ensure_ascii=False, indent=2)
        os.replace(tmp, CONFIG_FILE)

def get_cam_cfg(dev):
    dev = str(dev)
    with CFG_LOCK:
        c = CFG.setdefault("cameras", {}).setdefault(dev, {})
        c.setdefault("mic", "default")
        c.setdefault("timelapse", {"enable": False, "interval": 5})
        c.setdefault("motion", {
            "enable": False, "sensitivity": 50, "min_area_pct": 3,
            "action": "photo", "overlay": True, "cooldown": 10, "clip_len": 30
        })
        return json.loads(json.dumps(c))  # cópia

def set_cam_cfg(dev, updates: dict):
    dev = str(dev)
    with CFG_LOCK:
        c = CFG.setdefault("cameras", {}).setdefault(dev, {})
        for k, v in (updates or {}).items():
            if k in ("timelapse", "motion") and isinstance(v, dict):
                tgt = c.setdefault(k, {})
                tgt.update(v)
            else:
                c[k] = v
    _cfg_save()

def set_ui_cfg(updates: dict):
    with CFG_LOCK:
        CFG.setdefault("ui", {}).update(updates or {})
    _cfg_save()

def sanitize_dev(dev: str) -> str:
    return re.sub(r"[^0-9A-Za-z_\-\.]", "_", str(dev))

# ----------------- HTML -----------------
HTML = """<!doctype html>
<html lang="pt-br"><head><meta charset="utf-8">
<title>Mini MultiCam</title><meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="x-basepath" content="{{ basepath|e }}">
<style>
:root{--bg:#111;--fg:#eee;--card:#1a1a1a;--line:#252525;--tile:320px}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--fg);font-family:system-ui,Segoe UI,Arial}
header{padding:10px 14px;border-bottom:1px solid var(--line);position:sticky;top:0;background:#121212;z-index:2}
main{display:grid;grid-template-columns:300px 1fr;gap:16px;padding:16px} @media(max-width:1000px){main{grid-template-columns:1fr}}
.panel,.card{background:var(--card);border:1px solid var(--line);border-radius:10px;padding:12px}
.grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(var(--tile),1fr));gap:10px}
.stream{background:#000;border-radius:8px;overflow:hidden;border:1px solid var(--line)}
.stream header{display:flex;justify-content:space-between;align-items:center;background:#141414;padding:6px 8px}
.stream img{width:100%;display:block}
button,select,input{background:#222;color:var(--fg);border:1px solid var(--line);padding:6px 8px;border-radius:8px}
button{cursor:pointer} button:hover{background:#2b2b2b}
.thumb{display:flex;gap:8px;align-items:center}
.thumb img{width:96px;height:64px;object-fit:cover;border-radius:6px;border:1px solid var(--line)}
.row{display:flex;gap:8px;flex-wrap:wrap;align-items:center}
small.muted{color:#aaa}

/* Biblioteca agrupada por câmera + origem */
.cam-block{border:1px solid var(--line); border-radius:10px; padding:10px; margin-bottom:14px; background:#151515}
.cam-block h4{margin:4px 0 10px 0}
.cam-section{margin-top:10px}
.cam-items.grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(240px,1fr));gap:10px}
.cam-items.list{display:block}
.cam-items.list .thumb{padding:8px 0;border-bottom:1px solid var(--line)}
.cam-items.grid .thumb{position:relative; display:block;border:1px solid var(--line);border-radius:8px;overflow:hidden}
.cam-items.grid .thumb img{width:100%;height:auto;display:block}
.cam-items.grid .thumb div{padding:8px}
.selbox{position:absolute;top:6px;left:6px;background:#0009;border:1px solid var(--line);padding:4px 6px;border-radius:8px}
.selcount{margin-left:8px;color:#aaa}
</style>





</head>
<body>
<header><strong>Mini MultiCam</strong> <small id="status"></small></header>
<main>
  <section class="panel">
    <h3>Câmeras</h3>
    <div id="devs" class="row"></div>
    <div class="row" style="margin-top:8px">
      <button id="refresh">↻ Atualizar</button>
      <small class="muted">Marque para abrir o preview</small>
    </div>

    <h3 style="margin-top:12px">Layout</h3>
    <div class="row">
      <label>Tamanho do preview</label>
      <select id="previewSize">
        <option value="small">Pequeno</option>
        <option value="medium" selected>Médio</option>
        <option value="large">Grande</option>
        <option value="xlarge">Muito grande</option>
        <option value="xxlarge">Muito MUITO grande</option>
      </select>
      <button id="applyUi">Aplicar</button>
    </div>

    <h3 style="margin-top:12px">Biblioteca</h3>
    <div class="row">
      <label>Visualização</label>
      <select id="libMode">
        <option value="grid">Grid</option>
        <option value="list">Lista</option>
      </select>
      <label>De</label><input type="date" id="dateFrom">
      <label>Até</label><input type="date" id="dateTo">
      <button id="applyLib">Aplicar</button>
    </div>
    <div class="row" style="margin-top:8px">
      <button id="selAll">Selecionar tudo</button>
      <button id="selNone">Limpar</button>
      <button id="delSel">Apagar selecionados</button>
      <span class="selcount" id="selCount">0 selecionado(s)</span>
    </div>
  </section>

  <section style="display:grid;gap:16px">
    <div class="card">
      <h3>Pré-visualizações</h3>
      <div id="streams" class="grid"></div>
    </div>
    <div class="card">
      <h3>Biblioteca</h3>
      <div class="row">
        <button onclick="loadMedia()">Atualizar</button>
      </div>
      <div id="libWrap"><!-- blocos por câmera --></div>
    </div>
  </section>
</main>

<script>
// Helpers de basepath/URL/fetch
function _basepath(){
  const m = document.querySelector('meta[name="x-basepath"]');
  const b = (m && m.content) ? m.content : "";
  return (b || "").replace(/\/+$/,''); // remove barra no fim
}
function url(p){
  p = String(p||'');
  if(/^https?:\/\//i.test(p)) return p;
  p = p.replace(/^\/+/, ''); // remove barras iniciais
  const b = _basepath();
  return (b ? (b + '/') : '/') + p;
}
function jfetch(p, init){
  return fetch(url(p), init);
}

window.addEventListener('error', (e)=>{
  try { console.error('JS Error:', e.message, e.error); } catch(_) {}
  const msg = 'Erro JS: ' + (e.message || 'desconhecido');
  const el = document.querySelector('#status');
  if (el) { el.textContent = ' ' + msg; setTimeout(()=>{ el.textContent=''; }, 5000); }
});

const $ = s => document.querySelector(s);
function setStatus(t){ $('#status').textContent = ' '+t; setTimeout(()=>$('#status').textContent='', 3000); }

// Helpers
const sanitize = dev => dev.replaceAll('/','_');
const selected = new Set();

async function persistSelected(){
  const arr = [...selected];
  // backup local (segue funcionando offline/sem backend)
  localStorage.setItem('selectedDevs', JSON.stringify(arr));
  try{
    await jfetch('api/config', {
      method:'POST',
      headers:{'Content-Type':'application/json'},
      body: JSON.stringify({ ui: { selected_devs: arr } })
    });
  }catch(e){ /* silencioso */ }
}

function applySelectedFromConfig(){
  const fromServer = GLOBAL_CFG?.ui?.selected_devs;
  const fromLocal  = JSON.parse(localStorage.getItem('selectedDevs') || '[]');
  const src = Array.isArray(fromServer) ? fromServer : fromLocal;
  selected.clear();
  src.forEach(d => selected.add(d));
}

let AUDIO_OPTIONS = [];  // /api/audio
let GLOBAL_CFG = null;   // /api/config

// Biblioteca seleção
const SEL = new Set();  // "photos|name.jpg" ou "videos|name.mp4"
function selKey(kind, name){ return kind+'|'+name; }
function updateSelCount(){ $('#selCount').textContent = SEL.size + ' selecionado(s)'; }
$('#selAll').onclick = ()=>{ document.querySelectorAll('[data-kind][data-name]').forEach(e=>{ e.checked=true; SEL.add(selKey(e.dataset.kind, e.dataset.name)); }); updateSelCount(); };
$('#selNone').onclick = ()=>{ document.querySelectorAll('[data-kind][data-name]').forEach(e=>{ e.checked=false; }); SEL.clear(); updateSelCount(); };
$('#delSel').onclick = async ()=>{
  if(SEL.size===0){ setStatus('Nada selecionado'); return; }
  if(!confirm('Apagar definitivamente '+SEL.size+' item(ns)?')) return;
  const items = [...SEL].map(k=>{ const [kind,name]=k.split('|'); return {kind,name}; });
  const r = await jfetch('api/media/delete', {method:'POST', headers:{'Content-Type':'application/json'}, body: JSON.stringify({items})});
  const j = await r.json();
  if(j.ok){ setStatus('Apagados: '+j.deleted); SEL.clear(); updateSelCount(); loadMedia(); }
  else setStatus('Erro: '+(j.error||''));
};

function micOptionsHtml(selected){
  const opts = (AUDIO_OPTIONS.length? AUDIO_OPTIONS : ["default","none"]);
  return opts.map(v=>{
    const sel = (v===selected) ? ' selected' : '';
    return `<option value="${v}"${sel}>${v}</option>`;
  }).join("");
}
function applyPreviewSize(sz){
  let px = 320;
  if(sz==='small') px = 260;
  if(sz==='large') px = 480;
  if(sz==='xlarge') px = 720;
  if(sz==='xxlarge') px = 1100; // “Muito MUITO grande”
  document.documentElement.style.setProperty('--tile', px+'px');
}
function libMode(){ return $('#libMode').value === 'list' ? 'list' : 'grid'; }

// Dispositivos
async function listDevices(){
  const j = await (await jfetch('api/devices',{cache:'no-store'})).json();
  const wrap = $('#devs'); wrap.innerHTML='';
  const devs = j.devices || [];
  if(devs.length === 0){
    wrap.innerHTML = '<small>Nenhuma câmera.</small>';
    return;
  }
  devs.forEach(dev=>{
    const row = document.createElement('label');
    row.className = 'row'; row.style.gap = '6px';

    const cb = document.createElement('input');
    cb.type = 'checkbox';
    cb.checked = selected.has(dev);
    cb.onchange = (e)=>{
      if(e.target.checked){ selected.add(dev); addStream(dev); }
      else{ selected.delete(dev); removeStream(dev); }
      persistSelected();
    };

    const span = document.createElement('span');
    span.textContent = dev;
    row.appendChild(cb); row.appendChild(span);
    $('#devs').appendChild(row);
    if(cb.checked) addStream(dev);
  });
}
$('#refresh').onclick = listDevices;

// Pré-visualizações
function addStream(dev){
  const id = 'stream-'+sanitize(dev);
  if(document.getElementById(id)) return;

  const ccfg   = (GLOBAL_CFG && GLOBAL_CFG.cameras && GLOBAL_CFG.cameras[dev]) || {};
  const micSel = ccfg.mic || 'default';
  const tlCfg  = (ccfg.timelapse || {});
  const tlOn   = !!tlCfg.enable;
  const tlInt  = tlCfg.interval || 5;
  const mdCfg  = (ccfg.motion || {});
  const mdOn   = !!mdCfg.enable;
  const mdSens = mdCfg.sensitivity || 50;
  const mdAct  = mdCfg.action || 'photo';
  const mdOv   = (mdCfg.overlay!==false);
  const mdCd   = mdCfg.cooldown || 10;
  const mdLen  = mdCfg.clip_len || 30;

  const box = document.createElement('div');
  box.className = 'stream';
  box.id = id;

  const h = document.createElement('header');
  h.innerHTML = `<span>${dev}</span>
    <span class="row">
      <button onclick="photo('${dev}')">📷 Foto</button>
      <button onclick="recStart('${dev}')">⏺️ Gravar</button>
      <button onclick="recStop('${dev}')">⏹️ Parar</button>
    </span>`;

  const controls = document.createElement('div');
  controls.className = 'row';
  controls.style.padding = '6px 8px';
  controls.innerHTML = `
    <label>Mic</label>
    <select class="micSel">${micOptionsHtml(micSel)}</select>

    <label><input type="checkbox" class="tlToggle"${tlOn?' checked':''}> Timelapse</label>
    <input type="number" class="tlInt" min="1" value="${tlInt}" style="width:90px">

    <label><input type="checkbox" class="mdToggle"${mdOn?' checked':''}> Movimento</label>
    <label>Sens</label>
    <input type="range" class="mdSens" min="1" max="100" value="${mdSens}" style="width:140px">

    <label>Ação</label>
    <select class="mdAction">
      <option value="photo"${mdAct==='photo'?' selected':''}>Foto</option>
      <option value="video"${mdAct==='video'?' selected':''}>Vídeo</option>
    </select>

    <label>Cooldown (s)</label>
    <input type="number" class="mdCooldown" min="0" value="${mdCd}" style="width:80px">

    <label>Clip (s)</label>
    <input type="number" class="mdClip" min="5" value="${mdLen}" style="width:80px">

    <label><input type="checkbox" class="mdOverlay"${mdOv?' checked':''}> Overlays</label>

    <button class="applyCam">Aplicar</button>
  `;

['.micSel','.tlToggle','.tlInt','.mdToggle','.mdSens','.mdAction','.mdCooldown','.mdClip','.mdOverlay']
.forEach(sel=>{
  const el = controls.querySelector(sel);
  if(el){
    el.addEventListener('change', ()=> autosaveCam(dev, controls));
    el.addEventListener('input',  ()=> autosaveCam(dev, controls)); // sliders/number
  }
});


  const img = document.createElement('img');
  img.src = url('video_feed?dev='+encodeURIComponent(dev));

  box.appendChild(h);
  box.appendChild(controls);
  box.appendChild(img);
  $('#streams').appendChild(box);


  controls.querySelector('.applyCam').onclick = async ()=>{
    try{
      const micEl = controls.querySelector('.micSel');
      const mic = micEl ? micEl.value.trim() : (GLOBAL_CFG?.cameras?.[dev]?.mic || 'default');
      const tlE = !!controls.querySelector('.tlToggle')?.checked;
      const tlI = parseInt(controls.querySelector('.tlInt')?.value,10)||5;
      const mdE = !!controls.querySelector('.mdToggle')?.checked;
      const mdS = parseInt(controls.querySelector('.mdSens')?.value,10)||50;
      const mdA = controls.querySelector('.mdAction')?.value || 'photo';
      const mdO = !!controls.querySelector('.mdOverlay')?.checked;
      const mdC = Math.max(0, parseInt(controls.querySelector('.mdCooldown')?.value,10)||0);
      const mdL = Math.max(5, parseInt(controls.querySelector('.mdClip')?.value,10)||30);

      console.log('applyCam()', {dev, mic, tlE, tlI, mdE, mdS, mdA, mdO, mdC, mdL});

      const r = await jfetch('api/config', {
        method:'POST',
        headers:{'Content-Type':'application/json'},
        body: JSON.stringify({
          dev, mic,
          timelapse:{enable: tlE, interval: tlI},
          motion:{enable: mdE, sensitivity: mdS, action: mdA, overlay: mdO, cooldown: mdC, clip_len: mdL}
        })
      });
      const j = await r.json();
      setStatus(j.ok? 'config salva' : ('Erro ao salvar: '+(j.error||'')));
    }catch(err){
      console.error('applyCam error', err);
      setStatus('Erro JS ao aplicar: '+err);
    }
  };

}

function gatherCamConfig(dev, controls){
  const mic = controls.querySelector('.micSel')?.value?.trim() || (GLOBAL_CFG?.cameras?.[dev]?.mic || 'default');
  const tlE = !!controls.querySelector('.tlToggle')?.checked;
  const tlI = parseInt(controls.querySelector('.tlInt')?.value,10)||5;
  const mdE = !!controls.querySelector('.mdToggle')?.checked;
  const mdS = parseInt(controls.querySelector('.mdSens')?.value,10)||50;
  const mdA = controls.querySelector('.mdAction')?.value || 'photo';
  const mdO = !!controls.querySelector('.mdOverlay')?.checked;
  const mdC = Math.max(0, parseInt(controls.querySelector('.mdCooldown')?.value,10)||0);
  const mdL = Math.max(5, parseInt(controls.querySelector('.mdClip')?.value,10)||30);
  return {dev, mic, tlE, tlI, mdE, mdS, mdA, mdO, mdC, mdL};
}

let saveTimer = null;
async function autosaveCam(dev, controls){
  const p = gatherCamConfig(dev, controls);
  clearTimeout(saveTimer);
  saveTimer = setTimeout(async ()=>{
    try{
      const r = await jfetch('api/config', {
        method:'POST',
        headers:{'Content-Type':'application/json'},
        body: JSON.stringify({
          dev: p.dev, mic: p.mic,
          timelapse:{enable: p.tlE, interval: p.tlI},
          motion:{enable: p.mdE, sensitivity: p.mdS, action: p.mdA, overlay: p.mdO, cooldown: p.mdC, clip_len: p.mdL}
        })
      });
      const j = await r.json();
      if(!j.ok) setStatus('Erro ao salvar: '+(j.error||''));
    }catch(e){
      console.error('autosaveCam', e);
    }
  }, 300); // debounce
}



function removeStream(dev){
  const id = 'stream-'+sanitize(dev);
  const el = document.getElementById(id);
  if(el) el.remove();
}

// Ações
async function photo(dev){
  try{
    const r = await jfetch('api/photo', {
      method:'POST',
      headers:{'Content-Type':'application/json'},
      body: JSON.stringify({dev})
    });
    const j = await r.json();
    setStatus(j.ok?('Foto: '+j.file):('Erro: '+j.error));
    loadMedia();
  }catch(err){
    console.error('photo error', err);
    setStatus('Erro JS em Foto: '+err);
  }
}

async function recStart(dev){
  try{
    // feedback imediato para ver que o clique funcionou
    setStatus('Iniciando gravação…');
    const card = document.getElementById('stream-'+sanitize(dev));
    const micEl = card ? card.querySelector('.micSel') : null;
    const mic = (micEl && typeof micEl.value === 'string')
      ? micEl.value.trim()
      : ((GLOBAL_CFG && GLOBAL_CFG.cameras && GLOBAL_CFG.cameras[dev] && GLOBAL_CFG.cameras[dev].mic) || 'default');

    console.log('recStart()', { dev, mic });

    const r = await jfetch('api/record/start', {
      method:'POST',
      headers:{'Content-Type':'application/json'},
      body: JSON.stringify({dev, mic})
    });
    const j = await r.json();
    setStatus(j.ok?('Gravando: '+j.file):('Erro: '+j.error));
    loadMedia();
  }catch(err){
    console.error('recStart error', err);
    setStatus('Erro JS em Gravar: '+err);
  }
}

async function recStop(dev){
  try{
    console.log('recStop()', { dev });
    const r = await jfetch('api/record/stop', {
      method:'POST',
      headers:{'Content-Type':'application/json'},
      body: JSON.stringify({dev})
    });
    const j = await r.json();
    setStatus(j.ok?('Salvo: '+j.file):('Erro: '+j.error));
    loadMedia();
  }catch(err){
    console.error('recStop error', err);
    setStatus('Erro JS em Parar: '+err);
  }
}


// Biblioteca
function buildMediaQuery(){
  const df = $('#dateFrom').value;
  const dt = $('#dateTo').value;
  const p = new URLSearchParams();
  if(df) p.set('start', df);
  if(dt) p.set('end', dt);
  return 'api/media?'+p.toString();
}
async function loadMedia(){
  const j = await (await jfetch(buildMediaQuery(),{cache:'no-store'})).json();
  const wrap = $('#libWrap'); wrap.innerHTML = '';
  const mode = libMode();

  const cams = j.cameras || [];
  if(cams.length===0){
    wrap.innerHTML = '<small class="muted">Sem arquivos.</small>';
    return;
  }

  cams.forEach(cam=>{
    const blk = document.createElement('div');
    blk.className = 'cam-block';

    const h = document.createElement('h4');
    h.textContent = 'Câmera: '+cam;
    blk.appendChild(h);

    function section(title, arr, kind){
      if(!arr || !arr.length) return;
      const sec = document.createElement('div');
      sec.className = 'cam-section';
      sec.innerHTML = '<div><strong>'+title+'</strong></div>';
      const list = document.createElement('div');
      list.className = 'cam-items '+mode;
      arr.forEach(it=>{
        const d = document.createElement('div'); d.className='thumb';
        const ck = document.createElement('input'); ck.type='checkbox'; ck.className='selbox';
        ck.dataset.kind=kind; ck.dataset.name=it.name;
        ck.onchange = ()=>{ if(ck.checked) SEL.add(selKey(kind, it.name)); else SEL.delete(selKey(kind, it.name)); updateSelCount(); };
        if(mode==='grid'){ const wrapSel = document.createElement('label'); wrapSel.className='selbox'; wrapSel.appendChild(ck); d.appendChild(wrapSel); }
        else { d.prepend(ck); }
        d.innerHTML += `<img src="${url(it.thumb)}"><div>
          <div>${it.name}</div>
          <div><a href="${url(it.url)}" target="_blank">abrir</a></div></div>`;
        list.appendChild(d);
      });
      sec.appendChild(list);
      blk.appendChild(sec);
    }

    const bc = j.by_camera[cam] || {};
    section('Vídeos (manuais)',  bc.videos_user,   'videos');
    section('Vídeos (movimento)',bc.videos_motion, 'videos');
    section('Fotos (manuais)',   bc.photos_user,   'photos');
    section('Fotos (movimento)', bc.photos_motion, 'photos');
    section('Timelapse',         bc.timelapse,     'photos');

    wrap.appendChild(blk);
  });
}

// UI global
$('#applyUi').onclick = async ()=>{
  const sz = $('#previewSize').value;
  applyPreviewSize(sz);
  await jfetch('api/config', {method:'POST', headers:{'Content-Type':'application/json'},
    body: JSON.stringify({ui:{preview_size: sz}})});
  setStatus('layout atualizado');
};
$('#applyLib').onclick = async ()=>{
  const mode = $('#libMode').value;
  await jfetch('api/config', {method:'POST', headers:{'Content-Type':'application/json'},
    body: JSON.stringify({ui:{library_view: mode}})});
  loadMedia();
};

// Init
function applyLibModeToSelect(){
  const mode = GLOBAL_CFG?.ui?.library_view || 'grid';
  $('#libMode').value = mode;
}
async function loadAudioOptions(){
  try{
    const j = await (await jfetch('api/audio',{cache:'no-store'})).json();
    AUDIO_OPTIONS = [...(j.pulse||[]), ...(j.alsa||[]), 'none'];
  }catch(e){
    AUDIO_OPTIONS = ['default','none'];
  }
}
async function loadConfig(){
  try{
    GLOBAL_CFG = await (await jfetch('api/config',{cache:'no-store'})).json();
    const sz = GLOBAL_CFG?.ui?.preview_size || 'medium';
    $('#previewSize').value = sz;
    applyPreviewSize(sz);
    applySelectedFromConfig();
    applyLibModeToSelect();
  }catch(e){}
}
async function init(){
  await loadAudioOptions();
  await loadConfig();
  await listDevices();

  loadMedia();
}
init();
</script>

</body></html>
"""

# ----------------- Utils de mídia -----------------
def make_thumb_image(src, max_w=240):
    try:
        img = cv2.imread(src)
        if img is None: return None
        h, w = img.shape[:2]
        if w > max_w:
            s = max_w / float(w)
            img = cv2.resize(img, (int(w*s), int(h*s)), interpolation=cv2.INTER_AREA)
        name = os.path.basename(src)
        tname = name if name.lower().endswith(".jpg") else os.path.splitext(name)[0]+".jpg"
        tpath = os.path.join(MEDIA["thumbs"], tname)
        cv2.imwrite(tpath, img)
        return tpath
    except Exception:
        return None

def make_thumb_from_frame(frame, video_path):
    if frame is None: return
    name = os.path.splitext(os.path.basename(video_path))[0] + ".jpg"
    tpath = os.path.join(MEDIA["thumbs"], name)
    h, w = frame.shape[:2]
    if w > 240:
        s = 240/float(w)
        frame = cv2.resize(frame, (int(w*s), int(h*s)), interpolation=cv2.INTER_AREA)
    cv2.imwrite(tpath, frame)

# ----------------- Scanner de câmeras -----------------
def scan_linux_cams():
    devs = []
    for p in sorted(glob.glob("/dev/video*")):
        try:
            st = os.stat(p)
            if not stat.S_ISCHR(st.st_mode):
                continue
        except Exception:
            continue
        devs.append(p)
    return devs

# ----------------- Motion detector (boxes) -----------------
class MotionDetector:
    def __init__(self):
        self.bg = None
        self.last_boxes = []
        self.lock = threading.Lock()

    def process(self, frame, sensitivity=50, min_area_pct=3):
        try:
            h, w = frame.shape[:2]
            new_w = 320 if w > 320 else w
            if w > new_w:
                scale = new_w / float(w)
                small = cv2.resize(frame, (new_w, int(h*scale)), interpolation=cv2.INTER_AREA)
            else:
                small = frame
            gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (9,9), 0)

            if self.bg is None:
                self.bg = gray.astype("float32")
                with self.lock:
                    self.last_boxes = []
                return []

            cv2.accumulateWeighted(gray, self.bg, 0.05)
            bg_u8 = cv2.convertScaleAbs(self.bg)
            delta = cv2.absdiff(bg_u8, gray)

            thr_val = max(5, int(90 - float(sensitivity)*0.8))
            _, th = cv2.threshold(delta, thr_val, 255, cv2.THRESH_BINARY)
            th = cv2.dilate(th, None, iterations=2)
            contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            total = th.shape[0]*th.shape[1]
            area = sum(cv2.contourArea(c) for c in contours)
            area_pct = (area/max(1,total))*100.0
            boxes=[]
            if area_pct >= float(min_area_pct):
                gh, gw = th.shape[:2]
                sx = frame.shape[1]/float(gw)
                sy = frame.shape[0]/float(gh)
                for c in contours:
                    x,y,w0,h0 = cv2.boundingRect(c)
                    X = int(x*sx); Y = int(y*sy)
                    W = int(w0*sx); H = int(h0*sy)
                    if W>0 and H>0:
                        boxes.append((X,Y,W,H))

            with self.lock:
                self.last_boxes = boxes[:]
            return boxes
        except Exception:
            return []

    def get_boxes(self):
        with self.lock:
            return self.last_boxes[:]

# ----------------- Recorder (stdin + áudio com owner) -----------------

def list_alsa_capture_devices():
    try:
        r = subprocess.run(["arecord","-l"], capture_output=True, text=True)
    except Exception:
        return []
    devs=[]; card=None
    for ln in (r.stdout or "").splitlines():
        mcard = re.search(r"card\s+(\d+):\s*([^\s,]+)", ln)
        if mcard: card = mcard.group(2)
        mdev  = re.search(r"device\s+(\d+):", ln)
        if card and mdev:
            d = mdev.group(1)
            devs += [f"hw:CARD={card},DEV={d}", f"plughw:CARD={card},DEV={d}"]
    try:
        r2 = subprocess.run(["arecord","-L"], capture_output=True, text=True)
        for ln in (r2.stdout or "").splitlines():
            s = ln.strip()
            if s.startswith(("default:CARD=","sysdefault:CARD=","front:CARD=")):
                devs.append(s)
    except Exception:
        pass
    out=[]; seen=set()
    for d in devs:
        if d not in seen:
            seen.add(d); out.append(d)
    return out

def list_pulse_sources():
    try:
        r = subprocess.run(["pactl","list","short","sources"], capture_output=True, text=True)
    except Exception:
        return []
    out=["pulse"]
    for ln in (r.stdout or "").splitlines():
        cols = ln.split("\t")
        if len(cols)>=2:
            out.append("pulse:"+cols[1])
    return out

# ----------------- Recorder (stdin + áudio com owner, robusto) -----------------
def have_cmd(cmd):
    try:
        subprocess.run([cmd, "-version"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except Exception:
        return False

class Recorder:
    def __init__(self):
        self.proc_by_dev   = {}
        self.file_by_dev   = {}
        self.thread_by_dev = {}
        self.run_by_dev    = {}
        self.owner_by_dev  = {}
        self.stderr_buf    = {}   # dev -> str com cauda dos logs do ffmpeg
        self.lock = threading.Lock()

    def _stderr_tail(self, dev, limit=4000):
        try:
            buf = self.stderr_buf.get(dev, "")
            return buf[-limit:]
        except Exception:
            return ""

    def _spawn_stderr_drain(self, dev, proc):
        """Drena stderr do ffmpeg para evitar bloqueio de PIPE cheio."""
        from collections import deque
        dq = deque(maxlen=4000)
        self.stderr_buf[dev] = ""

        def _drain():
            try:
                while True:
                    if proc.poll() is not None and not proc.stderr:
                        break
                    chunk = proc.stderr.readline()
                    if not chunk:
                        if proc.poll() is not None:
                            break
                        time.sleep(0.05)
                        continue
                    try:
                        s = chunk.decode("utf-8", "ignore")
                    except Exception:
                        s = repr(chunk)
                    dq.extend(s)
                    self.stderr_buf[dev] = "".join(dq)
            except Exception:
                pass

        th = threading.Thread(target=_drain, daemon=True)
        th.start()

    def _probe_cam_dims(self, cam):
        w = int(cam.cap.get(cv2.CAP_PROP_FRAME_WIDTH)  or 0)
        h = int(cam.cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)
        fps = float(cam.cap.get(cv2.CAP_PROP_FPS) or 0) or 30.0
        if not w or not h:
            frm = None
            for _ in range(15):
                frm = cam.last_frame()
                if frm is not None: break
                time.sleep(0.1)
            if frm is None:
                return 1280, 720, fps
            h, w = frm.shape[:2]
        return int(w), int(h), float(fps)

    def _ffmpeg_cmd(self, w, h, fps, mic, out_path, audio_backend):
        # sem -shortest: evita encerrar se o áudio oscilar
        base = [
            "ffmpeg","-loglevel","error","-y",
            "-f","rawvideo","-pix_fmt","bgr24","-s",f"{w}x{h}","-r",str(fps),"-i","-",
        ]
        if audio_backend == "none":
            base += ["-an"]
        else:
            base += ["-f", audio_backend, "-thread_queue_size", "1024", "-i", mic]
        base += ["-c:v","libx264","-preset","veryfast","-crf","23","-pix_fmt","yuv420p"]
        if audio_backend != "none":
            base += ["-c:a","aac","-b:a","128k"]
        base += ["-movflags","+faststart", out_path]
        return base

    def _writer_loop(self, dev, cam, proc, fps):
        period = 1.0 / max(1.0, float(fps))
        next_t = time.time()
        try:
            while self.run_by_dev.get(dev, False):
                if proc.poll() is not None:
                    break
                frm = cam.last_frame()
                if frm is not None:
                    try:
                        proc.stdin.write(frm.tobytes())
                    except (BrokenPipeError, ValueError, OSError):
                        break
                next_t += period
                delay = next_t - time.time()
                if delay > 0: time.sleep(delay)
                else: next_t = time.time()
        finally:
            try:
                if proc.stdin:
                    proc.stdin.flush()
                    proc.stdin.close()
            except Exception:
                pass

    def _start_ffmpeg(self, dev, w, h, fps, mic, out_path):
        if not have_cmd("ffmpeg"):
            raise RuntimeError("ffmpeg não encontrado. Instale o pacote ffmpeg.")
        mic = (mic or "").strip()

        # ordem dos backends
        if not mic or mic.lower() == "none":
            backends = [("none", mic)]
        elif mic.lower().startswith("pulse"):
            backends = [("pulse", mic), ("alsa", mic), ("none", mic)]
        else:
            backends = [("alsa", mic), ("none", mic)]

        tried = []
        for backend, micname in backends:
            cmd = self._ffmpeg_cmd(w, h, fps, micname, out_path, backend)
            p = subprocess.Popen(
                cmd,
                stdin=subprocess.PIPE,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                bufsize=0
            )
            self._spawn_stderr_drain(dev, p)
            time.sleep(0.6)
            if p.poll() is None:
                return p, backend
            tried.append(f"[{backend}] {self._stderr_tail(dev)}")

        raise RuntimeError("ffmpeg não iniciou.\n" + "\n".join(tried))

    def is_recording(self, dev):
        dev = str(dev)
        with self.lock:
            p = self.proc_by_dev.get(dev)
        return p is not None and (p.poll() is None)

    def start(self, dev, mic="default", owner="user"):
        """INCLUIR ESTE MÉTODO — ele que faltava."""
        dev = str(dev)
        cam = get_cam(dev)

        # se já está gravando, devolve o arquivo atual
        if self.is_recording(dev):
            with self.lock:
                return os.path.basename(self.file_by_dev.get(dev) or "")

        w, h, fps = self._probe_cam_dims(cam)
        ts = datetime.now().strftime("%Y%m%d-%H%M%S")
        prefix = "video-user" if owner == "user" else "video-motion"
        out_path = os.path.join(MEDIA["videos"], f"{prefix}-{sanitize_dev(dev)}-{ts}.mp4")

        p, backend = self._start_ffmpeg(dev, w, h, fps, mic, out_path)

        with self.lock:
            self.proc_by_dev[dev] = p
            self.file_by_dev[dev] = out_path
            self.run_by_dev[dev]  = True
            self.owner_by_dev[dev]= owner

        th = threading.Thread(target=self._writer_loop, args=(dev, cam, p, fps), daemon=True)
        th.start()
        with self.lock:
            self.thread_by_dev[dev] = th

        if backend == "none":
            print(f"[Recorder] {dev}: gravando SEM ÁUDIO (fallback).")
        return os.path.basename(out_path)

    def stop(self, dev, owner=None, force=False):
        dev = str(dev)
        with self.lock:
            p  = self.proc_by_dev.get(dev)
            out = self.file_by_dev.get(dev)
            th = self.thread_by_dev.get(dev)
            cur_owner = self.owner_by_dev.get(dev)
            if (owner is not None) and (cur_owner is not None) and (cur_owner != owner) and (not force):
                raise RuntimeError(f"em uso por {cur_owner}")
            self.run_by_dev[dev] = False

        if not p:
            raise RuntimeError("não está gravando")

        if th:
            th.join(timeout=3.5)

        try:
            p.wait(timeout=6)
        except subprocess.TimeoutExpired:
            try:
                p.terminate(); p.wait(timeout=3)
            except subprocess.TimeoutExpired:
                p.kill()
                try: p.wait(timeout=2)
                except Exception: pass

        with self.lock:
            self.proc_by_dev.pop(dev, None)
            self.thread_by_dev.pop(dev, None)
            self.run_by_dev.pop(dev, None)
            self.owner_by_dev.pop(dev, None)

        if out:
            for _ in range(15):
                if os.path.isfile(out) and os.path.getsize(out) > 0:
                    return os.path.basename(out)
                time.sleep(0.1)
        err = self._stderr_tail(dev)
        raise RuntimeError(f"gravação não gerou arquivo.\n{err}")


REC = Recorder()

# ----------------- Timelapse -----------------
class Timelapser:
    def __init__(self, dev, interval=5):
        self.dev = str(dev)
        self.interval = max(1, int(interval))
        self.running = False
        self.lock = threading.Lock()
        self.th = None

    def start(self, interval=None):
        with self.lock:
            if interval is not None:
                self.interval = max(1, int(interval))
            if self.running:
                return True
            self.running = True
            self.th = threading.Thread(target=self._loop, daemon=True)
            self.th.start()
            return True

    def stop(self):
        with self.lock:
            self.running = False
        if self.th:
            self.th.join(timeout=1.0)

    def _loop(self):
        cam = get_cam(self.dev)
        while True:
            with self.lock:
                if not self.running: break
                interval = self.interval
            frame = cam.last_frame()
            if frame is not None:
                ts = datetime.now().strftime("%Y%m%d-%H%M%S")
                name = f"tl-{sanitize_dev(self.dev)}-{ts}.jpg"
                path = os.path.join(MEDIA["photos"], name)
                cv2.imwrite(path, frame)
                make_thumb_image(path)
            total = interval; step = 0.1; loops = int(total/step)
            for _ in range(max(1,loops)):
                with self.lock:
                    if not self.running: break
                time.sleep(step)

TIMERS = {}  # dev -> Timelapser
def get_timer(dev):
    dev=str(dev)
    if dev not in TIMERS:
        tcfg = get_cam_cfg(dev).get("timelapse", {})
        TIMERS[dev] = Timelapser(dev, interval=tcfg.get("interval",5))
    return TIMERS[dev]

# ----------------- Motion Controller -----------------
class MotionController:
    def __init__(self, dev):
        self.dev = str(dev)
        self.lock = threading.Lock()
        cfg = get_cam_cfg(self.dev).get("motion", {})
        self.enable = bool(cfg.get("enable", False))
        self.sens = int(cfg.get("sensitivity", 50))
        self.min_area = int(cfg.get("min_area_pct", 3))
        self.action = cfg.get("action", "photo")  # photo|video
        self.overlay = bool(cfg.get("overlay", True))
        self.cooldown = int(cfg.get("cooldown", 10))
        self.clip_len = int(cfg.get("clip_len", 30))
        self.last_photo_ts = 0.0
        self.stop_at = 0.0
        self.owned_record = False
        self.monitor_th = threading.Thread(target=self._monitor, daemon=True)
        self._running = True
        self.monitor_th.start()

    def update_cfg(self):
        cfg = get_cam_cfg(self.dev).get("motion", {})
        with self.lock:
            self.enable = bool(cfg.get("enable", False))
            self.sens = int(cfg.get("sensitivity", 50))
            self.min_area = int(cfg.get("min_area_pct", 3))
            self.action = cfg.get("action", "photo")
            self.overlay = bool(cfg.get("overlay", True))
            self.cooldown = int(cfg.get("cooldown", 10))
            self.clip_len = int(cfg.get("clip_len", 30))

    def on_boxes(self, boxes):
        if not self.enable:
            return
        active = bool(boxes)
        now = time.time()
        if not active:
            return
        if self.action == "photo":
            if now - self.last_photo_ts >= max(1, self.cooldown):
                self._take_photo()
                self.last_photo_ts = now
        else:  # video
            with self.lock:
                if not REC.is_recording(self.dev):
                    try:
                        mic = get_cam_cfg(self.dev).get("mic","default")
                        REC.start(self.dev, mic=mic, owner="motion")
                        self.owned_record = True
                    except Exception as e:
                        print(f"[Motion] start rec failed: {e}")
                        self.owned_record = False
                self.stop_at = max(self.stop_at, now + float(self.clip_len))

    def _monitor(self):
        while self._running:
            time.sleep(0.25)
            with self.lock:
                if self.owned_record and self.stop_at>0 and time.time() >= self.stop_at:
                    try:
                        fname = REC.stop(self.dev, owner="motion")
                        if fname:
                            frame = get_cam(self.dev).last_frame()
                            make_thumb_from_frame(frame, os.path.join(MEDIA["videos"], fname))
                    except Exception as e:
                        print(f"[Motion] stop rec failed: {e}")
                    finally:
                        self.owned_record = False
                        self.stop_at = 0.0

    def _take_photo(self):
        cam = get_cam(self.dev)
        frame = cam.last_frame()
        if frame is None:
            return
        ts = datetime.now().strftime("%Y%m%d-%H%M%S")
        name = f"photo-motion-{sanitize_dev(self.dev)}-{ts}.jpg"
        path = os.path.join(MEDIA["photos"], name)
        cv2.imwrite(path, frame)
        make_thumb_image(path)

    def stop(self):
        self._running = False

MOTIONS = {}  # dev -> MotionController
MOTION_LOCK = threading.Lock()
def get_motion_ctrl(dev):
    dev=str(dev)
    with MOTION_LOCK:
        if dev not in MOTIONS:
            MOTIONS[dev] = MotionController(dev)
        return MOTIONS[dev]

# ----------------- Captura em thread (preview) -----------------
CAMS = {}            # dev -> CameraStream
CAM_LOCK = threading.Lock()

class CameraStream:
    def __init__(self, device, width=1280, height=720, fps=30, jpeg_quality=80):
        self.device = device
        self.q = int(jpeg_quality)
        self.lock = threading.Lock()
        self.frame = None
        self.running = True
        self.cap = self._open(device, width, height, fps)
        self.mdet = MotionDetector()
        self.th = threading.Thread(target=self._loop, daemon=True)
        self.th.start()

    def _open(self, dev, w, h, fps):
        sys = platform.system().lower()
        backend = cv2.CAP_V4L2 if 'linux' in sys else 0
        dev_arg = dev if not str(dev).isdigit() else int(dev)
        cap = cv2.VideoCapture(dev_arg, backend)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH,  w)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)
        cap.set(cv2.CAP_PROP_FPS, float(fps))
        if not cap.isOpened():
            raise RuntimeError(f"Não abriu câmera: {dev}")
        return cap

    def _loop(self):
        ctrl = get_motion_ctrl(self.device)
        while self.running:
            ok, img = self.cap.read()
            if ok:
                with self.lock:
                    self.frame = img
                cfg = get_cam_cfg(self.device).get("motion", {})
                do_proc = bool(cfg.get("enable")) or bool(cfg.get("overlay"))
                boxes = []
                if do_proc:
                    boxes = self.mdet.process(
                        img,
                        sensitivity=int(cfg.get("sensitivity", 50)),
                        min_area_pct=int(cfg.get("min_area_pct", 3))
                    )
                ctrl.update_cfg()
                if cfg.get("enable"):
                    ctrl.on_boxes(boxes)  # só dispara ação quando detecção ligada
            else:
                time.sleep(0.02)


    def _draw_motion(self, f):
        boxes = self.mdet.get_boxes()
        if not boxes: return f
        for (x,y,w,h) in boxes:
            cv2.rectangle(f, (x,y), (x+w, y+h), (0,0,255), 2)
        cv2.putText(f, f"motion:{len(boxes)}", (10,22), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2, cv2.LINE_AA)
        return f

    def get_jpeg(self):
        with self.lock:
            f = None if self.frame is None else self.frame.copy()
        if f is None:
            return None
        mcfg = get_cam_cfg(self.device).get("motion", {})
        if mcfg.get("overlay", False):
            f = self._draw_motion(f)
        ok, buf = cv2.imencode(".jpg", f, [int(cv2.IMWRITE_JPEG_QUALITY), self.q])
        return buf.tobytes() if ok else None


    def last_frame(self):
        with self.lock:
            return None if self.frame is None else self.frame.copy()

    def stop(self):
        self.running = False
        try: self.th.join(timeout=1)
        except: pass
        try: self.cap.release()
        except: pass

def get_cam(dev):
    with CAM_LOCK:
        if dev not in CAMS:
            CAMS[dev] = CameraStream(dev)
        return CAMS[dev]

# ----------------- Biblioteca Helpers -----------------
def parse_info_from_name(name: str):
    """
    Retorna (origin, cam) a partir do nome:
      video-user-<cam>-YYYYMMDD-HHMMSS.mp4
      video-motion-<cam>-YYYYMMDD-HHMMSS.mp4
      rec-user-<cam>-YYYYMMDD-HHMMSS.mp4      (legado)
      rec-motion-<cam>-YYYYMMDD-HHMMSS.mp4    (legado)
      photo-user-<cam>-YYYYMMDD-HHMMSS.jpg
      photo-motion-<cam>-YYYYMMDD-HHMMSS.jpg
      tl-<cam>-YYYYMMDD-HHMMSS.jpg            => origin='timelapse'
    """
    base = os.path.basename(name)

    # vídeos (novo + legado)
    m = re.match(r"^(?:video|rec)-(user|motion)-(.+?)-\d{8}-\d{6}\.(?:mp4|mkv|mov)$", base, re.IGNORECASE)
    if m:
        origin = m.group(1).lower()   # 'user' | 'motion'
        cam = m.group(2)
        return origin, cam

    # fotos (movimento ou manual)
    m = re.match(r"^photo-(user|motion)-(.+?)-\d{8}-\d{6}\.jpg$", base, re.IGNORECASE)
    if m:
        origin = m.group(1).lower()
        cam = m.group(2)
        return origin, cam

    # timelapse
    m = re.match(r"^tl-(.+?)-\d{8}-\d{6}\.jpg$", base, re.IGNORECASE)
    if m:
        return "timelapse", m.group(1)

    # super-legado: rec-<cam>-..., photo-<cam>-..., tl-<cam>-...
    m = re.match(r"^(rec|photo|tl)-(.+?)-\d{8}-\d{6}\.(mp4|jpg)$", base, re.IGNORECASE)
    if m:
        kind, cam = m.group(1).lower(), m.group(2)
        origin = "timelapse" if kind == "tl" else "user"
        return origin, cam

    return "_unknown", "_unknown"


def in_date_range(path, start_d: date=None, end_d: date=None):
    try:
        ts = os.path.getmtime(path)
    except Exception:
        return True
    d = datetime.fromtimestamp(ts).date()
    if start_d and d < start_d: return False
    if end_d and d > end_d: return False
    return True

# ----------------- Flask -----------------

app = Flask(__name__)
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_port=1, x_prefix=1)


@app.get("/")
def index():
    basepath = request.headers.get("X-Forwarded-Prefix") or (request.script_root or "")
    return render_template_string(HTML, basepath=basepath)


@app.get("/api/devices")
def api_devices():
    if "linux" in platform.system().lower():
        devs = scan_linux_cams()
    else:
        devs = []
        for i in range(6):
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                devs.append(str(i))
                cap.release()
    return jsonify(devices=devs)

@app.get("/api/audio")
def api_audio():
    alsa = list_alsa_capture_devices()
    pulse = list_pulse_sources()
    return jsonify(alsa=alsa, pulse=pulse)

@app.get("/video_feed")
def video_feed():
    dev = request.args.get("dev")
    if not dev: return Response("falta dev", status=400)
    try:
        cam = get_cam(dev)
    except Exception as e:
        return Response(str(e), status=503)

    boundary = "frame"
    def gen():
        while True:
            jpg = cam.get_jpeg()
            if jpg is None:
                time.sleep(0.03); continue
            yield (b"--"+boundary.encode()+b"\r\n"
                   b"Content-Type: image/jpeg\r\n"
                   b"Content-Length: "+str(len(jpg)).encode()+b"\r\n\r\n"+jpg+b"\r\n")
    return Response(gen(), mimetype="multipart/x-mixed-replace; boundary=frame")

@app.post("/api/photo")
def api_photo():
    data = request.get_json(silent=True) or {}
    dev = data.get("dev") or request.args.get("dev")
    if not dev: return jsonify(ok=False, error="falta dev"), 400
    cam = get_cam(dev)
    frame = cam.last_frame()
    if frame is None: return jsonify(ok=False, error="sem frame"), 503
    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
    name = f"photo-user-{sanitize_dev(dev)}-{ts}.jpg"
    path = os.path.join(MEDIA["photos"], name)
    cv2.imwrite(path, frame)
    make_thumb_image(path)
    return jsonify(ok=True, file=name)

@app.post("/api/record/start")
def api_rec_start():
    data = request.get_json(silent=True) or {}
    dev = data.get("dev")
    mic = data.get("mic")
    if not dev: return jsonify(ok=False, error="falta dev"), 400
    _ = get_cam(dev)
    if not mic:
        mic = get_cam_cfg(dev).get("mic","default")
    try:
        fname = REC.start(dev, mic=mic, owner="user")
        return jsonify(ok=True, file=fname)
    except Exception as e:
        return jsonify(ok=False, error=str(e)), 500

@app.post("/api/record/stop")
def api_rec_stop():
    data = request.get_json(silent=True) or {}
    dev = data.get("dev")
    if not dev: return jsonify(ok=False, error="falta dev"), 400
    try:
        # force=True para sempre parar, mesmo se iniciou por movimento
        fname = REC.stop(dev, owner="user", force=True)
        if fname:
            frame = get_cam(dev).last_frame()
            make_thumb_from_frame(frame, os.path.join(MEDIA["videos"], fname))
        return jsonify(ok=True, file=fname)
    except Exception as e:
        return jsonify(ok=False, error=str(e)), 400

@app.get("/api/media")
def api_media():
    def _parse_d(s):
        try: return datetime.strptime(s, "%Y-%m-%d").date()
        except Exception: return None
    start_d = _parse_d(request.args.get("start", "") or "")
    end_d   = _parse_d(request.args.get("end", "") or "")

    by_cam = {}

    for p in sorted(glob.glob(os.path.join(MEDIA["videos"], "*.mp4")), reverse=True):
        if not in_date_range(p, start_d, end_d): continue
        name = os.path.basename(p)
        origin, cam = parse_info_from_name(name)
        t = os.path.join(MEDIA["thumbs"], os.path.splitext(name)[0]+".jpg")
        bc = by_cam.setdefault(cam, {"videos_user": [], "videos_motion": [], "photos_user": [], "photos_motion": [], "timelapse": []})
        item = {"name": name, "url": f"/media/videos/{name}", "thumb": f"/media/thumbs/{os.path.basename(t)}" if os.path.isfile(t) else ""}
        if origin == "motion": bc["videos_motion"].append(item)
        else: bc["videos_user"].append(item)

    for p in sorted(glob.glob(os.path.join(MEDIA["photos"], "*.jpg")), reverse=True):
        if not in_date_range(p, start_d, end_d): continue
        name = os.path.basename(p)
        origin, cam = parse_info_from_name(name)
        t = os.path.join(MEDIA["thumbs"], name)
        if not os.path.isfile(t):
            make_thumb_image(p)
        bc = by_cam.setdefault(cam, {"videos_user": [], "videos_motion": [], "photos_user": [], "photos_motion": [], "timelapse": []})
        item = {"name": name, "url": f"/media/photos/{name}", "thumb": f"/media/thumbs/{name}"}
        if origin == "motion": bc["photos_motion"].append(item)
        elif origin == "timelapse": bc["timelapse"].append(item)
        else: bc["photos_user"].append(item)

    cams = sorted(by_cam.keys())
    return jsonify(by_camera=by_cam, cameras=cams)

@app.post("/api/media/delete")
def api_media_delete():
    data = request.get_json(silent=True) or {}
    items = data.get("items") or []
    if not isinstance(items, list) or not items:
        return jsonify(ok=False, error="items vazios"), 400
    deleted = 0
    for it in items:
        kind = (it.get("kind") or "").strip()
        name = (it.get("name") or "").strip()
        if kind not in ("photos","videos"): continue
        if "/" in name or "\\" in name: continue
        base_dir = MEDIA[kind]
        path = os.path.join(base_dir, name)
        try:
            if os.path.isfile(path):
                os.remove(path)
                deleted += 1
                # apagar thumb
                if kind == "photos":
                    t = os.path.join(MEDIA["thumbs"], name if name.lower().endswith(".jpg") else os.path.splitext(name)[0]+".jpg")
                    if os.path.isfile(t): os.remove(t)
                else:
                    t = os.path.join(MEDIA["thumbs"], os.path.splitext(name)[0]+".jpg")
                    if os.path.isfile(t): os.remove(t)
        except Exception:
            pass
    return jsonify(ok=True, deleted=deleted)

@app.get("/media/<path:kind>/<path:name>")
def media(kind, name):
    base = MEDIA.get(kind)
    if not base: abort(404)
    return send_from_directory(base, name)

# -------- Config/Timelapse/UI/Motion --------
@app.get("/api/config")
def api_config_get():
    with CFG_LOCK:
        return jsonify(CFG)

@app.post("/api/config")
def api_config_post():
    data = request.get_json(silent=True) or {}
    dev = data.get("dev")
    if dev:
        updates = {}
        if "mic" in data: updates["mic"] = data["mic"]
        if "timelapse" in data and isinstance(data["timelapse"], dict):
            t = {}
            if "enable" in data["timelapse"]: t["enable"] = bool(data["timelapse"]["enable"])
            if "interval" in data["timelapse"]: t["interval"] = int(data["timelapse"]["interval"])
            updates["timelapse"] = t
        if "motion" in data and isinstance(data["motion"], dict):
            m = {}
            if "enable" in data["motion"]: m["enable"] = bool(data["motion"]["enable"])
            if "sensitivity" in data["motion"]: m["sensitivity"] = int(data["motion"]["sensitivity"])
            if "min_area_pct" in data["motion"]: m["min_area_pct"] = int(data["motion"]["min_area_pct"])
            if "action" in data["motion"]: m["action"] = data["motion"]["action"] if data["motion"]["action"] in ("photo","video") else "photo"
            if "overlay" in data["motion"]: m["overlay"] = bool(data["motion"]["overlay"])
            if "cooldown" in data["motion"]: m["cooldown"] = int(data["motion"]["cooldown"])
            if "clip_len" in data["motion"]: m["clip_len"] = int(data["motion"]["clip_len"])
            updates["motion"] = m

        set_cam_cfg(dev, updates)

        # timelapse apply
        tl = get_timer(dev)
        tcfg = get_cam_cfg(dev).get("timelapse", {})
        if tcfg.get("enable"):
            tl.start(tcfg.get("interval",5))
        else:
            tl.stop()

        # motion controller update
        get_motion_ctrl(dev).update_cfg()
        return jsonify(ok=True)

    ui = data.get("ui")
    if isinstance(ui, dict):
        updates = {}
        if "preview_size" in ui:
            sz = str(ui["preview_size"]).lower()
            if sz not in ("small","medium","large","xlarge","xxlarge"):
                return jsonify(ok=False, error="preview_size inválido"), 400
            updates["preview_size"] = sz
        if "library_view" in ui:
            lv = str(ui["library_view"]).lower()
            if lv not in ("grid","list"):
                return jsonify(ok=False, error="library_view inválido"), 400
            updates["library_view"] = lv

        if "selected_devs" in ui:
            sd = ui["selected_devs"]
            if not isinstance(sd, (list, tuple)):
                return jsonify(ok=False, error="selected_devs inválido"), 400
        # normaliza para strings
            updates["selected_devs"] = [str(s) for s in sd]

        if updates:
            set_ui_cfg(updates)
            return jsonify(ok=True)
    return jsonify(ok=False, error="payload inválido"), 400


@app.post("/api/timelapse/start")
def api_tl_start():
    data = request.get_json(silent=True) or {}
    dev = data.get("dev"); interval = int(data.get("interval",5))
    if not dev: return jsonify(ok=False, error="falta dev"), 400
    set_cam_cfg(dev, {"timelapse":{"enable": True, "interval": interval}})
    get_timer(dev).start(interval)
    return jsonify(ok=True)

@app.post("/api/timelapse/stop")
def api_tl_stop():
    data = request.get_json(silent=True) or {}
    dev = data.get("dev")
    if not dev: return jsonify(ok=False, error="falta dev"), 400
    set_cam_cfg(dev, {"timelapse":{"enable": False}})
    get_timer(dev).stop()
    return jsonify(ok=True)

def _cleanup():
    for c in list(CAMS.values()):
        try: c.stop()
        except: pass
    for t in list(TIMERS.values()):
        try: t.stop()
        except: pass
    for m in list(MOTIONS.values()):
        try: m.stop()
        except: pass

import atexit; atexit.register(_cleanup)

if __name__ == "__main__":
    _cfg_load()
    # timelapse auto-start
    for dev, dat in list(CFG.get("cameras", {}).items()):
        tl = dat.get("timelapse", {})
        if tl.get("enable"):
            get_timer(dev).start(tl.get("interval",5))
    app.run("0.0.0.0", 5000, threaded=True)
EOF






tee /etc/systemd/system/mirakocam.service >/dev/null <<'EOF'
[Unit]
Description=MirakoCAM Flask Service
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/root/
ExecStart=/usr/bin/python3 /root/app.py
Restart=always
RestartSec=5
Environment=PORT=5000

[Install]
WantedBy=multi-user.target
EOF






sudo systemctl daemon-reload
sudo systemctl enable mirakocam
sudo systemctl start mirakocam
sudo systemctl restart mirakocam





sudo systemctl status mirakocam
sudo journalctl -fu mirakocam











































































































